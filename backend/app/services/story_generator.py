"""
Story Generator Service
ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ì„±ì ì¸ ìŠ¤í† ë¦¬ ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤
"""

import os
from typing import Dict, List, Optional
from openai import OpenAI
from app.core.logging import app_logger as logger
from app.core.config import settings


class StoryGeneratorService:
    """ìŠ¤í† ë¦¬ ìƒì„± ì„œë¹„ìŠ¤ (LLM ê¸°ë°˜)"""

    def __init__(self):
        self.api_key = settings.OPENAI_API_KEY
        self.client = OpenAI(api_key=self.api_key) if self.api_key else None
        self.model = "gpt-4o"  # GPT-4o: ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ëª¨ë¸

    def generate_story(
        self,
        context: Dict,
        store_name: Optional[str] = None,
        store_type: Optional[str] = None,
        menu_categories: Optional[List[str]] = None,
        selected_trends: Optional[List[str]] = None,
        menu_text: Optional[str] = None
    ) -> str:
        """
        ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìŠ¤í† ë¦¬ ë¬¸êµ¬ ìƒì„±

        Args:
            context: Context Collectorì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´
            store_name: ë§¤ì¥ ì´ë¦„
            store_type: (ì‚¬ìš© ì•ˆ í•¨ - í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€ìš©)
            menu_categories: ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸
            selected_trends: ì‚¬ìš©ìê°€ ì„ íƒí•œ íŠ¸ë Œë“œ í‚¤ì›Œë“œ (ìš°ì„ ì ìœ¼ë¡œ ë°˜ì˜)
            menu_text: ì‹¤ì œ ë©”ë‰´ ì •ë³´ í…ìŠ¤íŠ¸ (ì˜ˆ: "ì•„ë©”ë¦¬ì¹´ë…¸(3,500ì›), ì¹´í˜ë¼ë–¼(4,000ì›)")

        Returns:
            ìƒì„±ëœ ìŠ¤í† ë¦¬ ë¬¸êµ¬ (1-2ë¬¸ì¥)
        """
        if not self.client:
            logger.warning("OpenAI client not initialized, returning mock story")
            return self._generate_mock_story(context)

        try:
            # Prompt ìƒì„± (store_type ì œê±°)
            prompt = self._build_prompt(context, store_name, menu_categories, selected_trends, menu_text)

            logger.info(f"Generating story with prompt: {prompt[:100]}...")

            # ë¡œê·¸: menu_text í™•ì¸
            if menu_text:
                logger.info(f"Menu text provided: {menu_text[:100]}...")
            else:
                logger.warning("No menu_text provided, using categories only")

            # GPT API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë§¤ì¥ì˜ ë§ˆì¼€íŒ… ë‹´ë‹¹ìì…ë‹ˆë‹¤. "
                                   "âš ï¸ ì ˆëŒ€ ê·œì¹™: ì œê³µëœ ë©”ë‰´ ëª©ë¡ì— ìˆëŠ” ë©”ë‰´ë§Œ ì–¸ê¸‰í•˜ì„¸ìš”. "
                                   "ëª©ë¡ì— ì—†ëŠ” ë©”ë‰´ë‚˜ 'ìŒë£Œ', 'ì»¤í”¼', 'ìŒì‹', 'í•œ ì”', 'ìš”ë¦¬' ê°™ì€ ì¼ë°˜ ë‹¨ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ì…ë‹ˆë‹¤. "
                                   "ì´ ê·œì¹™ì„ ì–´ê¸°ë©´ ì•ˆ ë©ë‹ˆë‹¤. ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ ë©”ë‰´ ì´ë¦„ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=150,
                temperature=0.2,  # ë” ë‚®ì¶¤ (0.3 â†’ 0.2)
                top_p=0.85,  # ë” ë³´ìˆ˜ì ìœ¼ë¡œ
                presence_penalty=0.6,
                frequency_penalty=0.3
            )

            story = response.choices[0].message.content.strip()
            logger.info(f"Story generated successfully: {story}")

            return story

        except Exception as e:
            logger.error(f"Failed to generate story with GPT: {e}")
            return self._generate_mock_story(context)

    def _build_prompt(
        self,
        context: Dict,
        store_name: Optional[str],
        menu_categories: Optional[List[str]],
        selected_trends: Optional[List[str]] = None,
        menu_text: Optional[str] = None
    ) -> str:
        """
        GPT í”„ë¡¬í”„íŠ¸ ìƒì„± (ì‹¤ì œ ë©”ë‰´ ê¸°ë°˜)

        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            store_name: ë§¤ì¥ ì´ë¦„
            menu_categories: ë©”ë‰´ ì¹´í…Œê³ ë¦¬
            selected_trends: ì‚¬ìš©ìê°€ ì„ íƒí•œ íŠ¸ë Œë“œ
            menu_text: ì‹¤ì œ ë©”ë‰´ ì •ë³´

        Returns:
            ìƒì„±ëœ í”„ë¡¬í”„íŠ¸
        """
        weather = context.get("weather", {})
        time_info = context.get("time_info", {})
        season = context.get("season", "")

        # ì„ íƒëœ íŠ¸ë Œë“œê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ íŠ¸ë Œë“œ ì‚¬ìš©
        if selected_trends:
            trends = selected_trends
        else:
            trends = context.get("trends", [])

        # ë‚ ì”¨ ì •ë³´
        weather_desc = weather.get("description", "ë§‘ìŒ")
        temperature = weather.get("temperature", 15)

        # ì‹œê°„ëŒ€ ì •ë³´
        period_kr = time_info.get("period_kr", "ì˜¤í›„")
        time_str = time_info.get("time_str", "")

        # ê³„ì ˆ ì •ë³´
        season_map = {
            "spring": "ë´„",
            "summer": "ì—¬ë¦„",
            "autumn": "ê°€ì„",
            "winter": "ê²¨ìš¸"
        }
        season_kr = season_map.get(season, "")

        # íŠ¸ë Œë“œ ì •ë³´
        trend_str = ", ".join(trends[:3]) if trends else ""

        # ë©”ë‰´ ì •ë³´ - menu_textê°€ í•„ìˆ˜!
        if not menu_text:
            logger.error("âŒ menu_text is required but not provided!")
            # ë©”ë‰´ê°€ ì—†ìœ¼ë©´ ë§¤ìš° ì¼ë°˜ì ì¸ ë¬¸êµ¬ë§Œ ë°˜í™˜
            return f"{weather_desc} {period_kr}, {store_name or 'ìš°ë¦¬ ë§¤ì¥'}ì—ì„œ íŠ¹ë³„í•œ ì‹œê°„ì„ ë³´ë‚´ë³´ì„¸ìš”."

        # ì‹¤ì œ ë©”ë‰´ ì •ë³´ ì‚¬ìš©
        menu_info = f"**ğŸ“‹ ë°˜ë“œì‹œ ì´ ë©”ë‰´ë§Œ ì‚¬ìš© (ì ˆëŒ€ ë‹¤ë¥¸ ê²ƒ ì–¸ê¸‰ ê¸ˆì§€!):**\n{menu_text}"

        prompt = f"""ë‹¹ì‹ ì€ {store_name or "ì´ ë§¤ì¥"}ì˜ ë§ˆì¼€íŒ… ë‹´ë‹¹ìì…ë‹ˆë‹¤.

{menu_info}

**í˜„ì¬ ìƒí™©:**
- ë‚ ì”¨: {weather_desc}, {temperature}ë„
- ì‹œê°„: {period_kr}
{f'- íŠ¸ë Œë“œ: {trend_str}' if trend_str else ''}

**âš ï¸ ì ˆëŒ€ ê·œì¹™ (ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•¨!):**
1. ìœ„ ë©”ë‰´ ëª©ë¡ì— ìˆëŠ” ë©”ë‰´ ì´ë¦„ë§Œ ì‚¬ìš© (ë‹¤ë¥¸ ê²ƒ ì ˆëŒ€ ê¸ˆì§€)
2. "ìŒë£Œ", "ì»¤í”¼", "ìŒì‹", "í•œ ì”", "ìš”ë¦¬" ê°™ì€ ì¼ë°˜ ë‹¨ì–´ ì ˆëŒ€ ê¸ˆì§€
3. {temperature}ë„ â†’ {"ë”°ëœ»í•œ ë©”ë‰´ë§Œ ì¶”ì²œ" if temperature <= 10 else "ì‹œì›í•œ ë©”ë‰´ë§Œ ì¶”ì²œ" if temperature >= 25 else "ë‚ ì”¨ì— ë§ëŠ” ë©”ë‰´ ì¶”ì²œ"}
4. 1-2ë¬¸ì¥, 50ì ì´ë‚´

â›” ì£¼ì˜: ìœ„ ë©”ë‰´ ëª©ë¡ì— ì—†ëŠ” ë©”ë‰´ëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”!

ì¶”ì²œ ë¬¸êµ¬ (ë©”ë‰´ ì´ë¦„ ë°˜ë“œì‹œ í¬í•¨):"""

        return prompt

    def _generate_mock_story(self, context: Dict) -> str:
        """
        Mock ìŠ¤í† ë¦¬ ìƒì„± (GPT ì‚¬ìš© ë¶ˆê°€ ì‹œ)

        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´

        Returns:
            Mock ìŠ¤í† ë¦¬ ë¬¸êµ¬
        """
        weather = context.get("weather", {})
        time_info = context.get("time_info", {})
        season = context.get("season", "")

        weather_desc = weather.get("description", "ë§‘ìŒ")
        temperature = weather.get("temperature", 15)
        period_kr = time_info.get("period_kr", "ì˜¤í›„")

        season_map = {
            "spring": "ë´„",
            "summer": "ì—¬ë¦„",
            "autumn": "ê°€ì„",
            "winter": "ê²¨ìš¸"
        }
        season_kr = season_map.get(season, "")

        # ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„±
        templates = [
            f"{weather_desc} {season_kr} {period_kr}, íŠ¹ë³„í•œ ë©”ë‰´ë¡œ ì—¬ìœ ë¥¼ ì¦ê²¨ë³´ì„¸ìš”.",
            f"{temperature}ë„ì˜ {season_kr} ë‚ ì”¨, ë§›ìˆëŠ” í•œ ë¼ ì–´ë– ì„¸ìš”?",
            f"{period_kr}ì˜ íŠ¹ë³„í•œ ìˆœê°„, ë”°ëœ»í•œ ë©”ë‰´ì™€ í•¨ê»˜í•˜ì„¸ìš”."
        ]

        import random
        story = random.choice(templates)

        logger.info(f"Mock story generated: {story}")
        return story

    def generate_menu_storytelling(
        self,
        menu_name: str,
        ingredients: List[str],
        origin: Optional[str] = None,
        history: Optional[str] = None
    ) -> str:
        """
        ë©”ë‰´ í´ë¦­ ì‹œ ë³´ì—¬ì¤„ ìŠ¤í† ë¦¬í…”ë§ ìƒì„±

        Args:
            menu_name: ë©”ë‰´ ì´ë¦„
            ingredients: ì¬ë£Œ ë¦¬ìŠ¤íŠ¸
            origin: ì›ì‚°ì§€
            history: ë©”ë‰´ ì—­ì‚¬

        Returns:
            ë©”ë‰´ ìŠ¤í† ë¦¬í…”ë§ ë¬¸êµ¬
        """
        if not self.client:
            logger.warning("OpenAI client not initialized, returning simple description")
            return f"{menu_name}ì€(ëŠ”) {', '.join(ingredients[:3])}ë¡œ ë§Œë“¤ì–´ì§„ íŠ¹ë³„í•œ ë©”ë‰´ì…ë‹ˆë‹¤."

        try:
            prompt = f"""ë‹¤ìŒ ë©”ë‰´ì— ëŒ€í•œ ê°ì„±ì ì¸ ìŠ¤í† ë¦¬ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë©”ë‰´ ì •ë³´:**
- ì´ë¦„: {menu_name}
- ì£¼ìš” ì¬ë£Œ: {', '.join(ingredients)}
{f'- ì›ì‚°ì§€: {origin}' if origin else ''}
{f'- ì—­ì‚¬: {history}' if history else ''}

**ì‘ì„± ê°€ì´ë“œ:**
1. ë©”ë‰´ì˜ ì—­ì‚¬ë‚˜ ìœ ë˜ë¥¼ ì°½ì˜ì ìœ¼ë¡œ ìŠ¤í† ë¦¬í…”ë§
2. ì¬ë£Œì˜ íŠ¹ì§•ê³¼ ì›ì‚°ì§€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
3. ê³ ê°ì´ "ì´ì•¼ê¸°ë¥¼ ì†Œë¹„"í•˜ë„ë¡ ê°ì„±ì ìœ¼ë¡œ ì‘ì„±
4. 2-3ë¬¸ì¥, ìµœëŒ€ 100ì

ì˜ˆì‹œ:
"ì´ ë©”ë‰´ëŠ” 1803ë…„ ì˜êµ­ì—ì„œ ì‹œì‘ë˜ì–´ ì „ ì„¸ê³„ë¡œ í¼ì§„ í´ë˜ì‹í•œ ë ˆì‹œí”¼ì…ë‹ˆë‹¤.
ì—„ì„ ëœ {ingredients[0]}ì™€ {ingredients[1] if len(ingredients) > 1 else 'ì¬ë£Œ'}ê°€ ì–´ìš°ëŸ¬ì ¸
íŠ¹ë³„í•œ ë§›ì„ ì„ ì‚¬í•©ë‹ˆë‹¤."

ìŠ¤í† ë¦¬:"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ìŒì‹ ì—­ì‚¬ì™€ ìŠ¤í† ë¦¬í…”ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=200,
                temperature=0.9
            )

            story = response.choices[0].message.content.strip()
            logger.info(f"Menu storytelling generated: {story}")

            return story

        except Exception as e:
            logger.error(f"Failed to generate menu storytelling: {e}")
            return f"{menu_name}ì€(ëŠ”) ì‹ ì„ í•œ ì¬ë£Œë¡œ ë§Œë“¤ì–´ì§„ íŠ¹ë³„í•œ ë©”ë‰´ì…ë‹ˆë‹¤."

    def generate_welcome_message(
        self,
        context: Dict,
        store_name: str,
        store_type: str = "ì¹´í˜"
    ) -> str:
        """
        ë©”ë‰´íŒ ìµœìƒë‹¨ í™˜ì˜ ë¬¸êµ¬ ìƒì„±

        ë‚ ì”¨, ê³„ì ˆ, ì‹œê°„, íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ì—¬ ê³ ê°ì„ í™˜ì˜í•˜ëŠ” ë§¤ë ¥ì ì¸ ë¬¸êµ¬ ìƒì„±

        Args:
            context: Context Collectorì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´
            store_name: ë§¤ì¥ ì´ë¦„
            store_type: ë§¤ì¥ íƒ€ì…

        Returns:
            í™˜ì˜ ë¬¸êµ¬ (1-2ë¬¸ì¥)
        """
        if not self.client:
            logger.warning("OpenAI client not initialized, returning mock welcome message")
            return self._generate_mock_welcome(context, store_name, store_type)

        try:
            weather = context.get("weather", {})
            time_info = context.get("time_info", {})
            season = context.get("season", "")
            trends = context.get("instagram_trends", []) or context.get("google_trends", []) or context.get("trends", [])

            # ë‚ ì”¨ ì •ë³´
            weather_desc = weather.get("description", "ë§‘ìŒ")
            temperature = weather.get("temperature", 15)

            # ì‹œê°„ëŒ€ ì •ë³´
            period_kr = time_info.get("period_kr", "ì˜¤í›„")
            weekday_kr = time_info.get("weekday_kr", "")

            # ê³„ì ˆ ì •ë³´
            season_map = {
                "spring": "ë´„",
                "summer": "ì—¬ë¦„",
                "autumn": "ê°€ì„",
                "winter": "ê²¨ìš¸"
            }
            season_kr = season_map.get(season, "")

            # íŠ¸ë Œë“œ ì •ë³´ (ìƒìœ„ 3ê°œ)
            trend_str = ", ".join(trends[:3]) if trends else ""

            prompt = f"""ë‹¤ìŒ ìƒí™©ì— ë§ëŠ” ë§¤ë ¥ì ì¸ í™˜ì˜ ë¬¸êµ¬ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë§¤ì¥ ì •ë³´:**
- ì´ë¦„: {store_name}
- íƒ€ì…: {store_type}

**í˜„ì¬ ìƒí™©:**
- ë‚ ì”¨: {weather_desc}, ì˜¨ë„ {temperature}ë„
- ê³„ì ˆ: {season_kr}
- ì‹œê°„ëŒ€: {period_kr}, {weekday_kr}
{f'- ì¸ê¸° íŠ¸ë Œë“œ: {trend_str}' if trend_str else ''}

**ì‘ì„± ê°€ì´ë“œ:**
1. í˜„ì¬ ë‚ ì”¨ì™€ ì‹œê°„ëŒ€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜
2. ê³ ê°ì—ê²Œ ë”°ëœ»í•˜ê³  ì¹œê·¼í•˜ê²Œ ë‹¤ê°€ê°€ê¸°
3. ë§¤ì¥ ë°©ë¬¸ì„ ìœ ë„í•˜ëŠ” ê°ì„±ì ì¸ í‘œí˜„
4. 1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ (ìµœëŒ€ 60ì)
5. ì´ëª¨ì§€ëŠ” ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
6. ë§¤ì¥ íƒ€ì…({store_type})ì— ë§ëŠ” ë¶„ìœ„ê¸°ë¡œ ì‘ì„±

ì¢‹ì€ ì˜ˆì‹œ:
- "ë¹„ ì˜¤ëŠ” ì›”ìš”ì¼ ì˜¤í›„, ë”°ëœ»í•œ ì»¤í”¼ í•œ ì”ìœ¼ë¡œ íë§í•˜ëŠ” ê±´ ì–´ë– ì„¸ìš”?"
- "ìŒ€ìŒ€í•œ ê°€ì„ ì•„ì¹¨, {store_name}ì—ì„œ íŠ¹ë³„í•œ í•˜ë£¨ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”."
- "ì£¼ë§ ì €ë…, ë§›ìˆëŠ” ìŒì‹ê³¼ í•¨ê»˜ ì—¬ìœ ë¡œìš´ ì‹œê°„ì„ ì¦ê²¨ë³´ì„¸ìš”."

í™˜ì˜ ë¬¸êµ¬:"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê°ì„±ì ì¸ í™˜ëŒ€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì´ ë§¤ì¥ì„ ë°©ë¬¸í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ë”°ëœ»í•œ ë¬¸êµ¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=100,
                temperature=0.8,
                presence_penalty=0.5
            )

            message = response.choices[0].message.content.strip()
            # ë”°ì˜´í‘œ ì œê±°
            message = message.strip('"').strip("'")

            logger.info(f"Welcome message generated: {message}")
            return message

        except Exception as e:
            logger.error(f"Failed to generate welcome message: {e}")
            return self._generate_mock_welcome(context, store_name, store_type)

    def _generate_mock_welcome(self, context: Dict, store_name: str, store_type: str) -> str:
        """Mock í™˜ì˜ ë¬¸êµ¬ ìƒì„±"""
        weather = context.get("weather", {})
        time_info = context.get("time_info", {})

        weather_desc = weather.get("description", "ë§‘ìŒ")
        period_kr = time_info.get("period_kr", "ì˜¤í›„")

        templates = [
            f"{weather_desc} {period_kr}, {store_name}ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.",
            f"{period_kr}ì˜ ì—¬ìœ ë¡œìš´ ì‹œê°„, {store_name}ì—ì„œ íŠ¹ë³„í•œ ìˆœê°„ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”.",
            f"ì˜¤ëŠ˜ë„ ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”. {store_name}ì´ í•¨ê»˜í•©ë‹ˆë‹¤."
        ]

        import random
        return random.choice(templates)

    def generate_menu_highlights(
        self,
        context: Dict,
        menus: List[Dict],
        store_type: str = "ì¹´í˜",
        max_highlights: int = 3
    ) -> List[Dict]:
        """
        ì‹œì¦Œ/ë‚ ì”¨ì— ë§ëŠ” ë©”ë‰´ í•˜ì´ë¼ì´íŠ¸ ìƒì„±

        í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ì— ê°€ì¥ ì í•©í•œ ë©”ë‰´ë¥¼ ì„ íƒí•˜ê³  ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±

        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            menus: ë©”ë‰´ ë¦¬ìŠ¤íŠ¸ [{"id": 1, "name": "ì•„ë©”ë¦¬ì¹´ë…¸", "category": "ì»¤í”¼", ...}]
            store_type: ë§¤ì¥ íƒ€ì…
            max_highlights: ìµœëŒ€ í•˜ì´ë¼ì´íŠ¸ ê°œìˆ˜

        Returns:
            í•˜ì´ë¼ì´íŠ¸ ë©”ë‰´ ë¦¬ìŠ¤íŠ¸ [{"menu_id": 1, "name": "ì•„ë©”ë¦¬ì¹´ë…¸", "reason": "..."}]
        """
        if not menus:
            logger.warning("No menus provided for highlights")
            return []

        if not self.client:
            logger.warning("OpenAI client not initialized, returning random highlights")
            return self._generate_mock_highlights(menus, max_highlights)

        try:
            import json
            from datetime import datetime

            weather = context.get("weather", {})
            time_info = context.get("time_info", {})
            season = context.get("season", "")
            trends = context.get("instagram_trends", []) or context.get("google_trends", []) or context.get("trends", [])

            # ë‚ ì”¨ ì •ë³´
            weather_desc = weather.get("description", "ë§‘ìŒ")
            temperature = weather.get("temperature", 15)

            # ì‹œê°„ëŒ€
            period_kr = time_info.get("period_kr", "ì˜¤í›„")
            hour = time_info.get("hour", 12)

            # ê³„ì ˆ
            season_map = {"spring": "ë´„", "summer": "ì—¬ë¦„", "autumn": "ê°€ì„", "winter": "ê²¨ìš¸"}
            season_kr = season_map.get(season, "")

            # ë‚ ì§œ ë° ì´ë²¤íŠ¸ ì •ë³´
            today = datetime.now()
            month = today.month
            day = today.day
            weekday_kr = time_info.get("weekday_kr", "")

            # íŠ¹ë³„ ì´ë²¤íŠ¸ ê°ì§€
            special_event = ""
            if month == 12:
                if day <= 25:
                    days_until_christmas = 25 - day
                    if days_until_christmas == 0:
                        special_event = "ì˜¤ëŠ˜ì€ í¬ë¦¬ìŠ¤ë§ˆìŠ¤!"
                    elif days_until_christmas <= 7:
                        special_event = f"í¬ë¦¬ìŠ¤ë§ˆìŠ¤ê°€ {days_until_christmas}ì¼ ë‚¨ìŒ"
                    elif days_until_christmas <= 14:
                        special_event = f"í¬ë¦¬ìŠ¤ë§ˆìŠ¤ê°€ 2ì£¼ë„ ì±„ ì•ˆ ë‚¨ìŒ"
                    else:
                        special_event = "í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì‹œì¦Œ"
                elif day > 25:
                    special_event = "ì—°ë§ ë¶„ìœ„ê¸°"
            elif month == 2 and day == 14:
                special_event = "ë°œë Œíƒ€ì¸ë°ì´"
            elif month == 3 and day == 14:
                special_event = "í™”ì´íŠ¸ë°ì´"
            elif month == 10 and day == 31:
                special_event = "í• ë¡œìœˆ"

            # ì˜¨ë„ êµ¬ê°„ íŒë‹¨
            if temperature < 0:
                temp_desc = "ì˜í•˜ì˜ ë§¤ì„œìš´ ì¶”ìœ„"
            elif temperature < 5:
                temp_desc = "ëª¸ì´ ì–¼ì–´ë¶™ëŠ” ì¶”ìš´ ë‚ ì”¨"
            elif temperature < 10:
                temp_desc = "ìŒ€ìŒ€í•œ ë‚ ì”¨"
            elif temperature < 15:
                temp_desc = "ì„ ì„ í•œ ë‚ ì”¨"
            elif temperature < 20:
                temp_desc = "í¬ê·¼í•œ ë‚ ì”¨"
            elif temperature < 25:
                temp_desc = "ë”°ëœ»í•œ ë‚ ì”¨"
            elif temperature < 30:
                temp_desc = "ë”ìš´ ë‚ ì”¨"
            else:
                temp_desc = "ë¬´ë”ìš´ í­ì—¼"

            # ë©”ë‰´ ì •ë³´ ì •ë¦¬
            menu_info = []
            for menu in menus[:20]:  # ìµœëŒ€ 20ê°œë§Œ ì „ì†¡ (í† í° ì ˆì•½)
                menu_info.append({
                    "id": menu.get("id"),
                    "name": menu.get("name"),
                    "category": menu.get("category", ""),
                    "description": menu.get("description", "")[:50]  # 50ìë¡œ ì œí•œ
                })

            # íŠ¸ë Œë“œ ë¬¸ìì—´ ìƒì„±
            trends_str = ', '.join(trends[:10]) if trends else 'ì—†ìŒ'

            prompt = f"""ë‹¤ìŒ ìƒí™©ì— ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ë©”ë‰´ {max_highlights}ê°œë¥¼ ì„ íƒí•˜ê³  ì¶”ì²œ ì´ìœ ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ğŸ“ í˜„ì¬ ìƒí™© (ë°˜ë“œì‹œ ì´ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í™œìš©í•˜ì„¸ìš”!):**
- ğŸŒ¡ï¸ ì˜¨ë„: {temperature}ë„ ({temp_desc})
- ğŸŒ¤ï¸ ë‚ ì”¨: {weather_desc}
- â„ï¸ ê³„ì ˆ: {season_kr}
- ğŸ• ì‹œê°„: {period_kr} ({hour}ì‹œê²½)
- ğŸ“… ìš”ì¼: {weekday_kr}
{'- ğŸ„ íŠ¹ë³„: ' + special_event if special_event else ''}
- ğŸ“Š ì¸ê¸° íŠ¸ë Œë“œ: {trends_str}

**ë©”ë‰´ ëª©ë¡:**
{json.dumps(menu_info, ensure_ascii=False, indent=2)}

**ğŸ¯ í•„ìˆ˜ ì‘ì„± ê·œì¹™ (í•˜ë‚˜ë¼ë„ ì–´ê¸°ë©´ ì•ˆ ë¨!):**

1ï¸âƒ£ **ê¸¸ì´**: ê° ì¶”ì²œ ì´ìœ ëŠ” **ë°˜ë“œì‹œ 40-60ì**ë¡œ ì‘ì„± (30ì ë¯¸ë§Œì€ ì ˆëŒ€ ê¸ˆì§€!)

2ï¸âƒ£ **êµ¬ì²´ì  ë°ì´í„° í™œìš© í•„ìˆ˜**:
   - ì˜¨ë„ {temperature}ë„ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ê±°ë‚˜ "{temp_desc}"ë¼ëŠ” í‘œí˜„ ì‚¬ìš©
   - ì¸ê¸° íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¤‘ ìµœì†Œ 1ê°œ ì´ìƒ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
{'   - "' + special_event + '" ì´ë²¤íŠ¸ ì–¸ê¸‰' if special_event else ''}
   - {period_kr} ì‹œê°„ëŒ€ì˜ íŠ¹ì„± ë°˜ì˜

3ï¸âƒ£ **ë‹¤ì–‘ì„±**: 3ê°œ ë©”ë‰´ì˜ ì¶”ì²œ ì´ìœ ê°€ ëª¨ë‘ ì™„ì „íˆ ë‹¤ë¥¸ êµ¬ì¡°ì™€ í‘œí˜„ì´ì–´ì•¼ í•¨

4ï¸âƒ£ **ê°ì„± í‘œí˜„**: êµ¬ì²´ì ì´ê³  ìƒìƒí•œ ê°ê°ì  í‘œí˜„ ì‚¬ìš© (ë§›, ì˜¨ë„, ë¶„ìœ„ê¸°)

**âœ… ì™„ë²½í•œ ì˜ˆì‹œ (ì´ë ‡ê²Œ ì‘ì„±í•˜ì„¸ìš”!):**

ì˜¨ë„ 2.8ë„, ê²¨ìš¸, ì˜¤í›„, í¬ë¦¬ìŠ¤ë§ˆìŠ¤ 23ì¼ ë‚¨ìŒ ìƒí™©ì´ë¼ë©´:
- "ì˜í•˜ ê·¼ì²˜ ë§¤ì„œìš´ ì¶”ìœ„({temperature}ë„)ë¥¼ ë…¹ì—¬ì¤„ ë”°ëœ»í•œ ê³ ê¸° ìš”ë¦¬, í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì¤€ë¹„ë¡œ ì§€ì¹œ ì˜¤í›„ì˜ ì™„ë²½í•œ ì—ë„ˆì§€ ì¶©ì „ì›" (55ì)
- "ì¶”ìš´ ê²¨ìš¸ ì˜¤í›„ SNS íŠ¸ë Œë“œ 1ìœ„ íŒŒìŠ¤íƒ€ë¡œ ëª¸ê³¼ ë§ˆìŒì„ ë”°ëœ»í•˜ê²Œ, í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë¶„ìœ„ê¸°ê¹Œì§€ ë”í•´ì§€ëŠ” íŠ¹ë³„í•œ í•œ ë¼" (58ì)
- "ì–¼ì–´ë¶™ì€ ëª¸ì„ ê°ì‹¸ëŠ” ëœ¨ëˆí•œ í† ë§ˆí†  êµ­ë¬¼ê³¼ ì«„ê¹ƒí•œ ë©´ë°œì˜ ì¡°í™”, {weekday_kr} ì˜¤í›„ í”¼ë¡œë¥¼ í’€ì–´ì£¼ëŠ” ì™„ë²½í•œ ì„ íƒ" (52ì)

**âŒ ë‚˜ìœ ì˜ˆì‹œ (ì´ë ‡ê²Œ ì ˆëŒ€ ì“°ì§€ ë§ˆì„¸ìš”!):**
- "ê²¨ìš¸ì— ì–´ìš¸ë¦¬ëŠ” ìŠ¤í…Œì´í¬" âŒ (14ì, ë„ˆë¬´ ì§§ìŒ, ì˜¨ë„ ë¯¸ì–¸ê¸‰, íŠ¸ë Œë“œ ë¯¸í™œìš©)
- "ì¶”ìš´ ë‚ ì”¨ì— ì¢‹ì€ íŒŒìŠ¤íƒ€" âŒ (13ì, êµ¬ì²´ì  ì˜¨ë„ ì—†ìŒ, ê°ì„± ì—†ìŒ)
- "í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë¶„ìœ„ê¸°ì™€ ì–´ìš¸ë¦¬ëŠ” ë©”ë‰´" âŒ (19ì, ì§§ìŒ, ë§›/ì‹ê° í‘œí˜„ ì—†ìŒ)
- "ê²¨ìš¸ ê°ì„±ì„ ìê·¹í•˜ëŠ” ìŒì‹" âŒ (14ì, ë„ˆë¬´ ì§§ê³  ì¶”ìƒì )

**ğŸ’¡ ìƒí™©ë³„ í•„ìˆ˜ í‘œí˜„ ê°€ì´ë“œ:**

ì˜¨ë„ë³„ (í˜„ì¬ {temperature}ë„):
- 5ë„ ë¯¸ë§Œ: "ì˜í•˜ ê·¼ì²˜ ë§¤ì„œìš´ ì¶”ìœ„", "ê½ê½ ì–¼ì–´ë¶™ì€ ëª¸ì„", "ì°¨ê°€ìš´ ê²¨ìš¸ë°”ëŒì— ë–¨ë¦¬ëŠ”"
- 5-10ë„: "ìŒ€ìŒ€í•œ ë‚ ì”¨ì— ì›€ì¸ ëŸ¬ë“ ", "ì°¬ë°”ëŒì´ ë¶€ëŠ” ë‚ ", "ê²¨ìš¸ ì¶”ìœ„ë¡œ ì–¼ì–´ë¶™ì€"
- 25ë„ ì´ìƒ: "ë¬´ë”ìš´ ì—´ê¸°ë¥¼ ì‹í˜€ì¤„", "ë•€ í˜ë¦¬ëŠ” ë”ìœ„ ì†ì—ì„œ", "ì—¬ë¦„ í­ì—¼ì„ ë‚ ë ¤ì¤„"

ì‹œê°„ëŒ€ë³„ (í˜„ì¬ {period_kr}):
- ì•„ì¹¨: "í•˜ë£¨ë¥¼ í™œê¸°ì°¨ê²Œ ì‹œì‘í• ", "ì•„ì¹¨ ì‹ì‚¬ë¡œ ë“ ë“ í•œ", "ìƒì¾Œí•œ ì•„ì¹¨ì˜ ì—ë„ˆì§€ì›"
- ì ì‹¬: "ì˜¤ì „ ì—…ë¬´ë¡œ ì§€ì¹œ ëª¸ì—", "ì ì‹¬ì‹œê°„ ìµœê³ ì˜ ì„ íƒ", "ì˜¤í›„ í™œë ¥ì„ ìœ„í•œ"
- ì˜¤í›„: "ë‚˜ë¥¸í•œ ì˜¤í›„ë¥¼ ê¹¨ì›Œì¤„", "ì˜¤í›„ ê°„ì‹ìœ¼ë¡œ ì™„ë²½í•œ", "ì €ë… ì „ í—ˆê¸°ë¥¼ ë‹¬ë˜ì¤„"
- ì €ë…: "í•˜ë£¨ì˜ í”¼ë¡œë¥¼ í’€ì–´ì£¼ëŠ”", "ì €ë… ì‹ì‚¬ë¡œ íŠ¹ë³„í•œ", "ë§ˆìŒê¹Œì§€ ë”°ëœ»í•´ì§€ëŠ”"

íŠ¸ë Œë“œ í™œìš© (ë°˜ë“œì‹œ í‚¤ì›Œë“œ 1ê°œ ì´ìƒ í¬í•¨):
- í˜„ì¬ íŠ¸ë Œë“œ: {trends_str}
- ì˜ˆ: "SNSì—ì„œ ê°€ì¥ í•«í•œ {trends[0] if trends else ''}ë¡œ", "ìš”ì¦˜ ëŒ€ì„¸ì¸ {trends[1] if len(trends) > 1 else ''}ì™€ í•¨ê»˜"

**ì‘ë‹µ í˜•ì‹:**
{{
  "highlights": [
    {{"menu_id": 1, "name": "ë©”ë‰´ëª…", "reason": "40-60ìì˜ ì™„ì „í•œ ë¬¸ì¥..."}},
    {{"menu_id": 2, "name": "ë©”ë‰´ëª…", "reason": "40-60ìì˜ ì™„ì „í•œ ë¬¸ì¥..."}},
    {{"menu_id": 3, "name": "ë©”ë‰´ëª…", "reason": "40-60ìì˜ ì™„ì „í•œ ë¬¸ì¥..."}}
  ]
}}

**ğŸš¨ ìµœì¢… í™•ì¸: ê° reasonì´ 40ì ì´ìƒì¸ì§€ ë°˜ë“œì‹œ í™•ì¸ í›„ ì‘ë‹µí•˜ì„¸ìš”!**

ì‘ë‹µ:"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë©”ë‰´ íë ˆì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ ê·œì¹™ì„ ì§€ì¼œì£¼ì„¸ìš”: 1) ê° ì¶”ì²œ ì´ìœ ëŠ” 40-60ìì˜ ì™„ì „í•œ ë¬¸ì¥, 2) ì œê³µëœ ì˜¨ë„, ì‹œê°„ëŒ€, íŠ¸ë Œë“œ í‚¤ì›Œë“œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ í™œìš©, 3) ê°ê°ì ì´ê³  ìƒìƒí•œ í‘œí˜„ ì‚¬ìš©, 4) ê° ë©”ë‰´ë§ˆë‹¤ ì™„ì „íˆ ë‹¤ë¥¸ êµ¬ì¡°ì™€ í‘œí˜„. 30ì ë¯¸ë§Œì˜ ì§§ì€ ì¶”ì²œì€ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=800,
                temperature=0.8,
                response_format={"type": "json_object"}
            )

            result = json.loads(response.choices[0].message.content)
            highlights = result.get("highlights", [])[:max_highlights]

            logger.info(f"Menu highlights generated: {len(highlights)} items")
            return highlights

        except Exception as e:
            logger.error(f"Failed to generate menu highlights: {e}")
            return self._generate_mock_highlights(menus, max_highlights)

    def _generate_mock_highlights(self, menus: List[Dict], max_highlights: int) -> List[Dict]:
        """Mock ë©”ë‰´ í•˜ì´ë¼ì´íŠ¸ ìƒì„±"""
        import random

        selected = random.sample(menus, min(max_highlights, len(menus)))

        reasons = [
            "ì˜¤ëŠ˜ì˜ ì¶”ì²œ ë©”ë‰´ì…ë‹ˆë‹¤",
            "ì¸ê¸° ë©”ë‰´ì…ë‹ˆë‹¤",
            "ì‹œì¦Œ í•œì • ë©”ë‰´ì…ë‹ˆë‹¤",
            "ë² ìŠ¤íŠ¸ì…€ëŸ¬ì…ë‹ˆë‹¤"
        ]

        highlights = []
        for menu in selected:
            highlights.append({
                "menu_id": menu.get("id"),
                "name": menu.get("name"),
                "reason": random.choice(reasons)
            })

        return highlights


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
story_generator_service = StoryGeneratorService()
