"""
Story Generator Service
ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ì„±ì ì¸ ìŠ¤í† ë¦¬ ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤
"""

import os
from typing import Dict, List, Optional
from openai import OpenAI
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from logger import app_logger as logger
from config import settings


class StoryGeneratorService:
    """ìŠ¤í† ë¦¬ ìƒì„± ì„œë¹„ìŠ¤ (LLM ê¸°ë°˜)"""

    def __init__(self):
        self.api_key = settings.OPENAI_API_KEY
        self.client = OpenAI(api_key=self.api_key) if self.api_key else None
        self.model = "gpt-3.5-turbo"  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸

    def generate_story(
        self,
        context: Dict,
        store_name: Optional[str] = None,
        store_type: Optional[str] = "ì¹´í˜",
        menu_categories: Optional[List[str]] = None
    ) -> str:
        """
        ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìŠ¤í† ë¦¬ ë¬¸êµ¬ ìƒì„±

        Args:
            context: Context Collectorì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´
            store_name: ë§¤ì¥ ì´ë¦„
            store_type: ë§¤ì¥ íƒ€ì… (ì¹´í˜, ë ˆìŠ¤í† ë‘ ë“±)
            menu_categories: ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸

        Returns:
            ìƒì„±ëœ ìŠ¤í† ë¦¬ ë¬¸êµ¬ (1-2ë¬¸ì¥)
        """
        if not self.client:
            logger.warning("OpenAI client not initialized, returning mock story")
            return self._generate_mock_story(context, store_type)

        try:
            # Prompt ìƒì„±
            prompt = self._build_prompt(context, store_name, store_type, menu_categories)

            logger.info(f"Generating story with prompt: {prompt[:100]}...")

            # GPT API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì¹´í˜/ë ˆìŠ¤í† ë‘ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                                   "ê³ ê°ì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ëŠ” ê°ì„±ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì¶”ì²œ ë¬¸êµ¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=150,
                temperature=0.8,  # ì°½ì˜ì„±ì„ ë†’ì„
                top_p=0.9,
                presence_penalty=0.6,
                frequency_penalty=0.3
            )

            story = response.choices[0].message.content.strip()
            logger.info(f"Story generated successfully: {story}")

            return story

        except Exception as e:
            logger.error(f"Failed to generate story with GPT: {e}")
            return self._generate_mock_story(context, store_type)

    def generate_multiple_stories(
        self,
        context: Dict,
        store_name: Optional[str] = None,
        store_type: Optional[str] = "ì¹´í˜",
        menu_categories: Optional[List[str]] = None,
        count: int = 3
    ) -> List[str]:
        """
        ì—¬ëŸ¬ ë²„ì „ì˜ ìŠ¤í† ë¦¬ ìƒì„± (A/B í…ŒìŠ¤íŠ¸ìš©)

        Args:
            context: Context Collectorì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´
            store_name: ë§¤ì¥ ì´ë¦„
            store_type: ë§¤ì¥ íƒ€ì…
            menu_categories: ë©”ë‰´ ì¹´í…Œê³ ë¦¬
            count: ìƒì„±í•  ìŠ¤í† ë¦¬ ê°œìˆ˜

        Returns:
            ìŠ¤í† ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        stories = []

        for i in range(count):
            try:
                story = self.generate_story(
                    context=context,
                    store_name=store_name,
                    store_type=store_type,
                    menu_categories=menu_categories
                )
                stories.append(story)
                logger.info(f"Generated story variant {i+1}/{count}")

            except Exception as e:
                logger.error(f"Failed to generate story variant {i+1}: {e}")
                stories.append(self._generate_mock_story(context, store_type))

        return stories

    def _build_prompt(
        self,
        context: Dict,
        store_name: Optional[str],
        store_type: str,
        menu_categories: Optional[List[str]]
    ) -> str:
        """
        GPT í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            store_name: ë§¤ì¥ ì´ë¦„
            store_type: ë§¤ì¥ íƒ€ì…
            menu_categories: ë©”ë‰´ ì¹´í…Œê³ ë¦¬

        Returns:
            ìƒì„±ëœ í”„ë¡¬í”„íŠ¸
        """
        weather = context.get("weather", {})
        time_info = context.get("time_info", {})
        season = context.get("season", "")
        trends = context.get("trends", [])

        # ë‚ ì”¨ ì •ë³´
        weather_desc = weather.get("description", "ë§‘ìŒ")
        temperature = weather.get("temperature", 15)

        # ì‹œê°„ëŒ€ ì •ë³´
        period_kr = time_info.get("period_kr", "ì˜¤í›„")
        time_str = time_info.get("time_str", "")

        # ê³„ì ˆ ì •ë³´
        season_map = {
            "spring": "ë´„",
            "summer": "ì—¬ë¦„",
            "autumn": "ê°€ì„",
            "winter": "ê²¨ìš¸"
        }
        season_kr = season_map.get(season, "")

        # íŠ¸ë Œë“œ ì •ë³´
        trend_str = ", ".join(trends[:3]) if trends else ""

        # ë©”ë‰´ ì¹´í…Œê³ ë¦¬
        menu_str = ", ".join(menu_categories) if menu_categories else "ìŒë£Œ"

        # ë¸Œëœë“œ í†¤ì•¤ë§¤ë„ˆ (ë§¤ì¥ íƒ€ì…ë³„ ì°¨ë³„í™”)
        tone_guide = {
            "ì¹´í˜": "ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ (ì˜ˆ: ~ì–´ë– ì„¸ìš”?, ~í•´ë³´ì„¸ìš”)",
            "ë ˆìŠ¤í† ë‘": "í’ˆê²©ìˆê³  ì „ë¬¸ì ì¸ í†¤ (ì˜ˆ: ~ì–´ë–»ìŠµë‹ˆê¹Œ?, ~ë§Œë“¤ì–´ë³´ì„¸ìš”)",
            "ë””ì €íŠ¸": "ë°œë„í•˜ê³  ë‹¬ì½¤í•œ í†¤ (ì˜ˆ: ~ì¦ê²¨ë´ìš”!, ~ëŠê»´ë³´ì„¸ìš”)",
            "ìˆ ì§‘": "í¸ì•ˆí•˜ê³  ìºì£¼ì–¼í•œ í†¤ (ì˜ˆ: ~ì–´ë•Œìš”?, ~í•¨ê»˜í•´ìš”)"
        }.get(store_type, "ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í†¤")

        # íŠ¸ë Œë“œê°€ ìˆì„ ê²½ìš° ê°•ì¡°
        trend_instruction = ""
        if trend_str:
            trend_instruction = f"""
**ğŸ”¥ íŠ¸ë Œë“œ í™œìš© (í•„ìˆ˜):**
- í˜„ì¬ ì¸ê¸° í‚¤ì›Œë“œ: {trend_str}
- ìœ„ íŠ¸ë Œë“œ ì¤‘ 1-2ê°œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸êµ¬ì— ë…¹ì—¬ë‚´ì„¸ìš”
- ì–µì§€ë¡œ ë¼ì›Œë„£ì§€ ë§ê³ , ë§¥ë½ì— ë§ê²Œ í™œìš©
- ì˜ˆ: "ìš”ì¦˜ ì¸ê¸°ì¸ {trends[0]}ì™€ í•¨ê»˜ {menu_str} ì–´ë– ì„¸ìš”?"
"""

        prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ëŠ” ê°ì„±ì ì¸ ì¶”ì²œ ë¬¸êµ¬ë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë§¤ì¥ ì •ë³´:**
- ë§¤ì¥ ì´ë¦„: {store_name or store_type}
- ë§¤ì¥ íƒ€ì…: {store_type}
- ì£¼ìš” ë©”ë‰´: {menu_str}
- ë¸Œëœë“œ í†¤: {tone_guide}

**í˜„ì¬ ìƒí™©:**
- ë‚ ì”¨: {weather_desc}, ì˜¨ë„ {temperature}ë„
- ê³„ì ˆ: {season_kr}
- ì‹œê°„ëŒ€: {period_kr} ({time_str})
{trend_instruction}

**ì‘ì„± ê°€ì´ë“œ:**
1. {tone_guide}ë¡œ ì‘ì„±
2. í˜„ì¬ ë‚ ì”¨, ê³„ì ˆ, ì‹œê°„ëŒ€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ê¸°
3. íŠ¸ë Œë“œ í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ 1-2ê°œ ë°˜ë“œì‹œ í™œìš© (ìì—°ìŠ¤ëŸ½ê²Œ)
4. êµ¬ì²´ì ì¸ ë©”ë‰´ë¥¼ ì–¸ê¸‰í•˜ì—¬ êµ¬ë§¤ ìš•êµ¬ ìê·¹
5. 1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ (ìµœëŒ€ 60ì)
6. ì´ëª¨ì§€ëŠ” ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ

ì˜ˆì‹œ:
- "ë¹„ ì˜¤ëŠ” ê°€ì„ ì˜¤í›„, ë”°ëœ»í•œ ì•„ë©”ë¦¬ì¹´ë…¸ í•œ ì”ê³¼ í•¨ê»˜ ì—¬ìœ ë¥¼ ëŠê»´ë³´ì„¸ìš”."
- "ìŒ€ìŒ€í•œ ê²¨ìš¸ ì•„ì¹¨, ë‹¬ì½¤í•œ ì¹´í˜ëª¨ì¹´ë¡œ í•˜ë£¨ë¥¼ ì‹œì‘í•˜ëŠ” ê±´ ì–´ë– ì„¸ìš”?"
- "ë”ìš´ ì—¬ë¦„ ì ì‹¬, ì‹œì›í•œ ì•„ì´ìŠ¤ ìŒë£Œë¡œ ë”ìœ„ë¥¼ ë‚ ë ¤ë³´ì„¸ìš”."
- "ìš”ì¦˜ í•«í•œ ë”¸ê¸° ì‹œì¦Œ, ì‹ ì„ í•œ ë”¸ê¸° ë””ì €íŠ¸ë¡œ ë‹¬ì½¤í•œ ì˜¤í›„ ì‹œê°„ ë§Œë“¤ì–´ë³´ì„¸ìš”."

ë¬¸êµ¬:"""

        return prompt

    def _generate_mock_story(self, context: Dict, store_type: str = "ì¹´í˜") -> str:
        """
        Mock ìŠ¤í† ë¦¬ ìƒì„± (GPT ì‚¬ìš© ë¶ˆê°€ ì‹œ)

        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            store_type: ë§¤ì¥ íƒ€ì…

        Returns:
            Mock ìŠ¤í† ë¦¬ ë¬¸êµ¬
        """
        weather = context.get("weather", {})
        time_info = context.get("time_info", {})
        season = context.get("season", "")

        weather_desc = weather.get("description", "ë§‘ìŒ")
        temperature = weather.get("temperature", 15)
        period_kr = time_info.get("period_kr", "ì˜¤í›„")

        season_map = {
            "spring": "ë´„",
            "summer": "ì—¬ë¦„",
            "autumn": "ê°€ì„",
            "winter": "ê²¨ìš¸"
        }
        season_kr = season_map.get(season, "")

        # ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„±
        templates = [
            f"{weather_desc} {season_kr} {period_kr}, ë”°ëœ»í•œ ìŒë£Œ í•œ ì” ì–´ë– ì„¸ìš”?",
            f"{temperature}ë„ì˜ {season_kr} ë‚ ì”¨, {store_type}ì—ì„œ ì—¬ìœ ë¥¼ ì¦ê²¨ë³´ì„¸ìš”.",
            f"{period_kr}ì˜ íŠ¹ë³„í•œ ìˆœê°„, ë§›ìˆëŠ” ë©”ë‰´ì™€ í•¨ê»˜í•˜ì„¸ìš”."
        ]

        import random
        story = random.choice(templates)

        logger.info(f"Mock story generated: {story}")
        return story

    def generate_menu_storytelling(
        self,
        menu_name: str,
        ingredients: List[str],
        origin: Optional[str] = None,
        history: Optional[str] = None
    ) -> str:
        """
        ë©”ë‰´ í´ë¦­ ì‹œ ë³´ì—¬ì¤„ ìŠ¤í† ë¦¬í…”ë§ ìƒì„±

        Args:
            menu_name: ë©”ë‰´ ì´ë¦„
            ingredients: ì¬ë£Œ ë¦¬ìŠ¤íŠ¸
            origin: ì›ì‚°ì§€
            history: ë©”ë‰´ ì—­ì‚¬

        Returns:
            ë©”ë‰´ ìŠ¤í† ë¦¬í…”ë§ ë¬¸êµ¬
        """
        if not self.client:
            logger.warning("OpenAI client not initialized, returning simple description")
            return f"{menu_name}ì€(ëŠ”) {', '.join(ingredients[:3])}ë¡œ ë§Œë“¤ì–´ì§„ íŠ¹ë³„í•œ ë©”ë‰´ì…ë‹ˆë‹¤."

        try:
            prompt = f"""ë‹¤ìŒ ë©”ë‰´ì— ëŒ€í•œ ê°ì„±ì ì¸ ìŠ¤í† ë¦¬ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë©”ë‰´ ì •ë³´:**
- ì´ë¦„: {menu_name}
- ì£¼ìš” ì¬ë£Œ: {', '.join(ingredients)}
{f'- ì›ì‚°ì§€: {origin}' if origin else ''}
{f'- ì—­ì‚¬: {history}' if history else ''}

**ì‘ì„± ê°€ì´ë“œ:**
1. ë©”ë‰´ì˜ ì—­ì‚¬ë‚˜ ìœ ë˜ë¥¼ ì°½ì˜ì ìœ¼ë¡œ ìŠ¤í† ë¦¬í…”ë§
2. ì¬ë£Œì˜ íŠ¹ì§•ê³¼ ì›ì‚°ì§€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
3. ê³ ê°ì´ "ì´ì•¼ê¸°ë¥¼ ì†Œë¹„"í•˜ë„ë¡ ê°ì„±ì ìœ¼ë¡œ ì‘ì„±
4. 2-3ë¬¸ì¥, ìµœëŒ€ 100ì

ì˜ˆì‹œ:
"ì´ ë©”ë‰´ëŠ” 1803ë…„ ì˜êµ­ì—ì„œ ì‹œì‘ë˜ì–´ ì „ ì„¸ê³„ë¡œ í¼ì§„ í´ë˜ì‹í•œ ë ˆì‹œí”¼ì…ë‹ˆë‹¤.
ì—„ì„ ëœ {ingredients[0]}ì™€ {ingredients[1] if len(ingredients) > 1 else 'ì¬ë£Œ'}ê°€ ì–´ìš°ëŸ¬ì ¸
íŠ¹ë³„í•œ ë§›ì„ ì„ ì‚¬í•©ë‹ˆë‹¤."

ìŠ¤í† ë¦¬:"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ìŒì‹ ì—­ì‚¬ì™€ ìŠ¤í† ë¦¬í…”ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=200,
                temperature=0.9
            )

            story = response.choices[0].message.content.strip()
            logger.info(f"Menu storytelling generated: {story}")

            return story

        except Exception as e:
            logger.error(f"Failed to generate menu storytelling: {e}")
            return f"{menu_name}ì€(ëŠ”) ì‹ ì„ í•œ ì¬ë£Œë¡œ ë§Œë“¤ì–´ì§„ íŠ¹ë³„í•œ ë©”ë‰´ì…ë‹ˆë‹¤."


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
story_generator_service = StoryGeneratorService()
