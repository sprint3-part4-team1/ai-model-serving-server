"""
LLM Router
ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ëª¨ë¸ ì„ íƒ ë° Fallback ì²˜ë¦¬
"""

import time
from enum import Enum
from typing import Dict, Any, Optional
import json

from .gpt5_provider import GPT5Provider
from .gpt4_provider import GPT4Provider
from .gemini_provider import GeminiProvider


class ModelPriority(Enum):
    """ëª¨ë¸ ìš°ì„  ìˆœìœ„"""
    PRIMARY = 1    # GPT-5.1
    SECONDARY = 2  # GPT-4.1
    TERTIARY = 3   # Gemini 2.5 Flash

class LLMRouter:
    """
    LLM ë¼ìš°í„°
    - ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ëª¨ë¸ ì„ íƒ
    - ìë™ Fallback
    - ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    """

    def __init__(self):
        self.providers = {
            ModelPriority.PRIMARY: GPT5Provider(),
            ModelPriority.SECONDARY: GPT4Provider(),
            ModelPriority.TERTIARY: GeminiProvider()
        }
        self.metrics = [] # ì„±ëŠ¥ ì¸¡ì • ë°ì´í„°

    def create_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """
        ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ëª¨ë¸ í˜¸ì¶œ
        ì‹¤íŒ¨ ì‹œ ìë™ Fallback
        
        Args:
            prompt (str): ì…ë ¥ í”„ë¡¬í”„íŠ¸
            **kwargs: ëª¨ë¸ë³„ ì¶”ê°€ íŒŒë¼ë¯¸í„°
        
        Returns:
            dict: {
                "response": "LLM ì‘ë‹µ",
                "model_used": "gpt-5-mini",
                "elapsed_time": 1.23,
                "success": True
            }
        """
        errors = []

        for priority in ModelPriority:
            provider = self.providers[priority]
            model_name = provider.get_model_name()

            # Health check
            if not provider.is_available():
                error_msg = f"{model_name} ì‚¬ìš© ë¶ˆê°€"
                print(f"âš ï¸ {error_msg}")
                errors.append(error_msg)
                continue

            try:
                print(f"ğŸ”„ {model_name} í˜¸ì¶œ ì¤‘...")
                start_time = time.time()

                response = provider.create_response(prompt, **kwargs)

                elapsed = time.time() - start_time

                # ë©”íŠ¸ë¦­ ì €ì¥
                metric = {
                    "model": model_name,
                    "elapsed_time": elapsed,
                    "success": True,
                    "timestamp": time.time(),
                    "priority": priority.value
                }
                self.log_metric(metric)

                print(f"âœ… {model_name} ì‘ë‹µ ì„±ê³µ ({elapsed:.2f}s)")

                return {
                    "response": response,
                    "model_used": model_name,
                    "elapsed_time": elapsed,
                    "success": True
                }
            
            except Exception as e:
                error_msg = f"{model_name} ì‹¤íŒ¨: {str(e)}"
                print(f"âŒ {error_msg}")
                errors.append(error_msg)

                # ì‹¤íŒ¨ ë©”íŠ¸ë¦­ ì €ì¥
                self.log_metric({
                    "model": model_name,
                    "success": False,
                    "error": str(e),
                    "timestamp": time.time(),
                    "priority": priority.value
                })

                continue
                
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨
        raise Exception(f"ëª¨ë“  LLM ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€. ì—ëŸ¬: {errors}")
    
    def parse_json_response(self, response_dict: Dict[str, Any]) -> Dict[str, Any]:
        """
        LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±
        
        Args:
            response_dict: create_response()ì˜ ë°˜í™˜ê°’
        
        Returns:
            dict: íŒŒì‹±ëœ JSON + ë©”íƒ€ë°ì´í„°
        """
        response_text = response_dict['response']
        model_used = response_dict['model_used']

        # ì‚¬ìš©í•œ providerë¡œ íŒŒì‹±
        for provider in self.providers.values():
            if provider.get_model_name() == model_used:
                parsed = provider.parse_json_response(response_text)
                return {
                    "data": parsed,
                    "model_used": model_used,
                    "elapsed_time": response_dict['elapsed_time']
                }
        
        raise ValueError(f"Unknown model: {model_used}")
    
    def log_metric(self, metric: Dict[str, Any]):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥"""
        self.metrics.append(metric)

    def get_performance_summary(self) -> Dict[str, Any]:
        """
        ì„±ëŠ¥ ìš”ì•½ ë¦¬í¬íŠ¸

        Returns:
            dict: {
                "gpt-5-mini": {
                    "calls": 10,
                    "success_rate": 0.9,
                    "avg_time": 1.23
                },
                ...
            }
        """
        summary = {}

        for provider in self.providers.values():
            model_name = provider.get_model_name()
            model_metrics = [m for m in self.metrics if m['model'] == model_name]

            if not model_name:
                continue

            successful = [m for m in model_metrics if m.get('success', False)]

            summary[model_name] = {
                "total_calls": len(model_metrics),
                "successful_calls": len(successful),
                "success_rate": len(successful) / len(model_metrics) if model_metrics else 0,
                "avg_time": sum(m['elapsed_time'] for m in successful) / len(successful) if successful else 0,
                "cost_per_1k": provider.get_cost_per_1k_tokens()
            }

            return summary
        
    def save_metrics(self, filepath: str = "metrics.json"):
        """ë©”íŠ¸ë¦­ì„ íŒŒì¼ë¡œ ì €ì¥"""
        with open(filepath, 'w') as f:
            json.dump({
                "metrics": self.metrics,
                "summary": self.get_performance_summary()
            }, f, indent=2)
        print(f"ğŸ“Š ë©”íŠ¸ë¦­ ì €ì¥: {filepath}")

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_llm_router = None

def get_llm_router():
    """LLM ë¼ìš°í„° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _llm_router
    if _llm_router is None:
        _llm_router = LLMRouter()
    return _llm_router